---
layout: single
title: "[병렬및분산시스템] 2장 GPU 및 CUDA 개요"
excerpt: "2장 GPU 및 CUDA 개요"
date: 2021-11-06T00:00:00+09:00
toc: true
toc_sticky: true
use_math: true
categories:
  - 전공
  - 병렬및분산시스템
tags:
  - 전공
  - 병렬및분산시스템
---

## CPU vs GPU

#### CPU

- 2004년까지 싱글코어 기반 구조 위에서 성능 향상 노력
    - CPU의 frequency(clock rate)를 향상시킴
    - frequency : 단위 시간동안 얼마나 많은 명령어를 처리할 수 있는가
    - frequency를 높이면 CPU의 처리 속도가 빨라짐
- Power Wall 제약(4Ghz)에 의한 클록 향상의 한계
    - power wall :  CPU의 clock rate를 증가시키면 전력 소모량이 증가 → 발열이 늘어남
    특정 clock 이상부터는 CPU의 전력소모량을 효율적으로 줄이기 어려워짐
    
    ![Untitled 0](https://user-images.githubusercontent.com/60471550/235724336-b9cea588-4dc0-4d38-8cb7-52a5bb84bbef.png)
    
    P : 전력 소모량
    
    a : 트랜지스터 집적도
    
    C : capacitance(전기용량)
    
    f : frequency(clock rate)
    
    V : 공급전압
    
    - clock rate를 올리면 전력 소모량이 올라감
    - 전력소모량이 오르는 것을 막고 싶으면 frequency가 오른만큼 공급 전압을 줄여야함
    - 공급 전압을 낮추다보면 누수전류량이 상승
        - 전압이 약해지면서 전류가 중간에 새는 문제
- 코어 숫자 증가 외에 HW instruction set 추가 필요
    - CPU는 운영체제를 포함한 컴퓨터의 전반적이 관리를 수행
    - 관리와 관련된 명령어들인 HW instruction set을 CPU에 가지고 있어야함
    - 컴퓨터의 성능 발전, 운영체제 복잡, 컴퓨터와 연결하는 디바이스의 종류 증가로 HW instruction set의 종류와 개수가 급격히 증가함
- 캐시 크기 증대의 어려움
- 메인 메모리 규격 변경의 비탄력성
    - CPU는 메인메모리와 연계해서 작업을 해야함
    - CPU의 성능을 올리려면 DRAM의 규격과 성능도 바뀌어야하지만 제조사가 다르므로 규격 변경이 어려움

![Untitled 1](https://user-images.githubusercontent.com/60471550/235724339-087a3ec2-0a9f-4dfb-b17b-ec0406de6155.png)

#### GPU

- 제품 안에 보드, 메모리, GPU를 포함, 규격 변경이 자유로움
- 연산 효율 증가만을 고려하여 코어 추가 가능
- 캐시 크기 증대의 용이함
- 대규모 데이터 병렬 처리에 유리

![Untitled 2](https://user-images.githubusercontent.com/60471550/235724341-e57c2e9c-47ab-4633-b5a3-e139e6848650.png)

![Untitled 3](https://user-images.githubusercontent.com/60471550/235724351-46a64e2e-eb0d-411e-8378-1a2e5d95a2f5.png)

![Untitled 4](https://user-images.githubusercontent.com/60471550/235724354-070482bd-0fef-4da6-8be6-811df3bbcaa6.png)

## CUDA

#### CUDA란 무엇인가?

- Parallel computing platform
- NVIDIA에 의해서 개발된 병렬 프로그래밍 모델 아키텍쳐
- 범용 연산을 GPU의 first-class capabilities로 고려하는 접근 방식
- C/C++, Fortran, Python 등의 언어로 구현 가능

![Untitled 5](https://user-images.githubusercontent.com/60471550/235724358-32e168c9-7cca-48a5-85ec-cc2f45d5d34a.png)

## GPU-CUDA의 장점

#### 병렬 프로그램의 확장성

- 대규모 데이터를 멀티스레드로 실행하여 처리
- GPU의 성능과 비례하여 병렬 연산 능력을 발휘
- 단순히 코어 수를 증가시키는 것으로 연산 시간 절감

#### 저렴한 가격

- 메인스트림 CPU 가격과 GPU 가격은 비슷한 수준
- 단일 GPU로 여러 대의 CPU를 사용하는 것과 동일한 연산 능력 제공

#### 편리한 설치

- CPU기반 클러스터 환경 구축시 다양한 보조 장치 필요(수-수십대 이상의 CPU, 쿨러, Rack 등)
- GPU는 그래픽 카드 한장 장착으로 해결
- 확장이 용이함

## CPU 기반 데이터 처리

1. 입력과 출력에 사용할 메모리를 할당한다
2. 처리하고자 하는 데이터를 메모리에 입력한다
3. 연산을 하고자 메모리에 있는 데이터를 CPU(레지스터)로 가져온다
4. 정수 연산은 ALU에서, 실수 연산은 FPU에서 처리한다
5. 처리된 레지스터의 값을 메모리로 출력한다
6. 사용한 메모리를 해재한다

![Untitled 6](https://user-images.githubusercontent.com/60471550/235724360-9c295018-742e-4430-ad77-26ce7ca04e27.png)

## 멀티코어 CPU 기반(4스레드) 데이터 처리

1. 입력과 출력에 사용하는 메모리를 할당한다
2. 처리하고자 하는 데이터를 메모리에 입력한다
3. 연산을 하고자 데이터를 4등분하여 각각의 코어에 가져온다
4. 데이터를 4개의 스레드로 처리한다
5. 처리된 4개의 데이터를 병합한다
6. 결과를 메모리에 출력한다

![Untitled 7](https://user-images.githubusercontent.com/60471550/235724362-216e679c-a7b3-4445-b6b9-a9c6f35aa445.png)

## GPU-CUDA 기반 데이터 처리

1. 그래픽 카드 메모리 공간을 할당한다
2. 호스트 메인 메모리의 입력 데이터를 그래픽 카드의 메모리로 복사한다
3. GPU 코어를 이용하여 병렬처리를 수행한다
4. 처리된 결과를 그래픽 카드의 메모리에서 호스트 메인 메모리로 복사한다

![Untitled 8](https://user-images.githubusercontent.com/60471550/235724365-0b0cc294-07d2-4f59-8a06-73ddf9f92350.png)

## GPU-CUDA 기반 데이터 병렬 처리

- CUDA에서도 멀티코어 CPU와 같이 작업을 분할하고 스레드를 생성하여 병렬로 처리하는 과정을 진행
- RTX3090 기준 총 10496개의 CUDA cores로 데이터가 입력되어 동작

![Untitled 9](https://user-images.githubusercontent.com/60471550/235724368-9426a6aa-066c-4f91-abe1-14aad9882bdb.png)

## CUDA 데이터 전송 부하

- GPU 기반 데이터 처리 시 호스트 메인 메모리와 그래픽 카드 메인 메모리 사이에 데이터 복사 과정이 추가로 발생
- 연산량이 적은 응용을 실행하는 경우 CPU기반 처리가 GPU기반 처리보다 더 빠를 수 있음

![Untitled 10](https://user-images.githubusercontent.com/60471550/235724370-db301b07-ab60-45b8-a3b0-16e209eae2cd.png)

## CUDA 적용이 유리항 응용

- GPU 연산 능력이 메모리 간 데이터 전송 오버헤드를 넘어서는 응용
- 연산 종류는 적고, 처리 데이터량은 많아서 한번의 연산 시간이 오래 걸리는 응용
- 동영상 인코딩, 디코딩, 영상 처리 응용
- 3D 게임
- 물리, 확학, 생물학 등 자연과학 시뮬레이션
- 머신러닝 등의 인공지능 기반 응용

![Untitled 11](https://user-images.githubusercontent.com/60471550/235724375-d6e1709f-7ab3-445d-bf53-38e884efaa09.png)

## NVIDIA GPU 아키텍쳐

- NVIDIA 지포스 8800GTX(G80) CUDA Thread Computing Pipeline

![Untitled 12](https://user-images.githubusercontent.com/60471550/235724386-a8481d75-0dc6-4f7f-9610-26327c15c07f.png)

###### Streaming Processor(SP)

- GPU 연산을 수행하는 최소 unit
- 데이터를 연산하기 위한 여러 모듈 포함(FPU, ALU, LSU)

###### Streaming Multiprocessor(SM)

- 여러개의 SP를 포함(8800GTX : 8개)
- SP를 제어하기 위한 캐시 포함
- 스레드 간 데이터 공유를 위한 shared memeory 운용

![Untitled 13](https://user-images.githubusercontent.com/60471550/235724388-e2586cec-4d8c-42bb-b25c-95af97137a2a.png)

![Untitled 14](https://user-images.githubusercontent.com/60471550/235724390-aacfb41f-80d6-4dae-9e8f-0280fd7ed969.png)

###### Fermi 아키텍쳐 (GF100, GTX400계열)

- 2010에 발표, 하나의 SM에 32개의 SP포함, 총 512개의 CUDA 코어 보유
- 2006년 8800GTX의 코어수의 4배로 증가

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/917c509c-63f1-4e42-9dda-525757195b19/Untitled.png)

###### Ampere 아키텍쳐 (GA102, RTX30계열)

- 2020에 발표, 42개의 TPC, 84개의 SM포함
- 각 SM에는 128개의 SP포함, FP32/INT32 operation 동시 처리 수행
- 그 외 각 SM은 4개의 3세대 Tensor Core, 1개의 2세대 RT Core 포함
- 총 10,490개의 CUDA 코어 포함

![Untitled 15](https://user-images.githubusercontent.com/60471550/235724400-6c6fbf33-b9e6-45a8-a90b-c3ad403fbf54.png)

![Untitled 16](https://user-images.githubusercontent.com/60471550/235724404-5547071b-7059-45af-8efd-d6048313fac9.png)